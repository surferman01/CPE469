# Epidemic Algorithm Notes

Epidemic Algorithms for Replicated Database Management

## Problem

- Efficiently updating multiple copied databases with new information and ensuring they are synced

### Factors

- time required for update to propagate to all sites
- network traffic generated by single update

### Trials

1. Direct mail: send the updated contents directly to every other database
2. Anti-entropy: every site randomly chooses another and exchanged database data, resolving differences between the 2
3. Rumor mongering: site with new data periodically, randomly, chooses another site to share data with until it has tried the same spot x times

### Terminology

- Infective: site with new data that it wants to share
- Susceptable: site that does not have new info
- Removed: recieved update and is not willing to share

- anti-entropy is a site with only infective or susceptable clients
ex)
When anti-entropy is used as a backup mechanism, there is a significant advantage in using a complex epidemic such as rumor mongering rather than direct mail for initial distribution of updates.

- residue: how much longer after everyone has gotten the update does data linger / checks still occur
- traffic: how much network traffic impact the protocol creates

ex)
Recall that with respect to an individual update, a database is either susceptible (it does not know the update), infective (it knows the update and is actively sharing it with others), or removed (it knows the update but is not spreading it)

## Push - Pull

- Like github, determining whether to take data from one source or another based on the timestamp
- use pull or push-pull rather than push when anti-entropy is used as a backup to some other distribution mechanism
  - this is very taxing
  - use checksums so we dont need to constantly send the entire db over the network

ex)
Two sites s and s' perform anti-entropy by first exchanging
recent update lists, using the lists to update their databases and checksums, and then comparing checksums. Only if the checksums disagree do the sites compare their entire databases

- for this, use a recent update list so that the changes which is bound by the expected distribution time

## Gossip / Rumor spreading

### Variations

- feedback vs blind
  - feedback
    - sender loses interest in the rumor if the recipient does not respond to it (it already has heard the rumor)
  - Blind
    - There is a 1/k chance that the rumor is dropped by sender regardless of response

- Counter vs coin
  - counter
    - instead of 1/k chance, make it lose interest if k recipients dont respond
    - combine counter with blind to make it infective regardless of responses

- Push vs pull
  - pull is good since it will find information that has multiple rumors heard

### Deletion / Death Certs

- When you remove an entry, you need to propagate it as though it was data since table removals will be thought of as out of date entries
  - give it a 'death certificate' w a timestamp
  - now how do we re-use this space?
    - one way is to just wait for the cert. to replace all the older data on other machines and then let it expire after x time (days perhaps)

- give death certs. an activiation time as well to prevent accidentally reinstating a deleted item since adding a death cert to a new database updates its original timestamp
